{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MatChain by API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illlustrates how to match two datasets A and B with MatChain's API and gives some information about the used algorithms and its parameters.\n",
    "\n",
    "Firstly, change to MatChain's main directory and import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\repos\\matchain\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matchain.api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets A and B used in this notebook contain bibliographic information about scientific articles. A and B are given in the form of CSV files and are read into Pandas' dataframes. The column 'id' refers to the row number but is not required and can be omitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/Structured/DBLP-ACM'\n",
    "dfa = pd.read_csv(f'{data_dir}/tableA.csv', index_col='id')\n",
    "dfb = pd.read_csv(f'{data_dir}/tableB.csv', index_col='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>semantic integration of environmental models f...</td>\n",
       "      <td>d. scott mackay</td>\n",
       "      <td>sigmod record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estimation of query-result distribution and it...</td>\n",
       "      <td>viswanath poosala , yannis e. ioannidis</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incremental maintenance for non-distributive a...</td>\n",
       "      <td>themistoklis palpanas , richard sidle , hamid ...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cost-based selection of path expression proces...</td>\n",
       "      <td>zhao-hui tang , georges gardarin , jean-robert...</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmarking spatial join operations with spat...</td>\n",
       "      <td>erik g. hoel , hanan samet</td>\n",
       "      <td>vldb</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "0   semantic integration of environmental models f...   \n",
       "1   estimation of query-result distribution and it...   \n",
       "2   incremental maintenance for non-distributive a...   \n",
       "3   cost-based selection of path expression proces...   \n",
       "4   benchmarking spatial join operations with spat...   \n",
       "\n",
       "                                              authors          venue  year  \n",
       "id                                                                          \n",
       "0                                     d. scott mackay  sigmod record  1999  \n",
       "1             viswanath poosala , yannis e. ioannidis           vldb  1996  \n",
       "2   themistoklis palpanas , richard sidle , hamid ...           vldb  2002  \n",
       "3   zhao-hui tang , georges gardarin , jean-robert...           vldb  1996  \n",
       "4                          erik g. hoel , hanan samet           vldb  1995  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the wasa2 object-oriented workflow management ...</td>\n",
       "      <td>gottfried vossen , mathias weske</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a user-centered interface for querying distrib...</td>\n",
       "      <td>isabel f. cruz , kimberly m. james</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world wide database-integrating the web , corb...</td>\n",
       "      <td>athman bouguettaya , boualem benatallah , lily...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xml-based information mediation with mix</td>\n",
       "      <td>chaitan baru , amarnath gupta , bertram lud &amp;#...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ccube constraint object-oriented database ...</td>\n",
       "      <td>alexander brodsky , victor e. segal , jia chen...</td>\n",
       "      <td>international conference on management of data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "id                                                      \n",
       "0   the wasa2 object-oriented workflow management ...   \n",
       "1   a user-centered interface for querying distrib...   \n",
       "2   world wide database-integrating the web , corb...   \n",
       "3            xml-based information mediation with mix   \n",
       "4   the ccube constraint object-oriented database ...   \n",
       "\n",
       "                                              authors  \\\n",
       "id                                                      \n",
       "0                    gottfried vossen , mathias weske   \n",
       "1                  isabel f. cruz , kimberly m. james   \n",
       "2   athman bouguettaya , boualem benatallah , lily...   \n",
       "3   chaitan baru , amarnath gupta , bertram lud &#...   \n",
       "4   alexander brodsky , victor e. segal , jia chen...   \n",
       "\n",
       "                                             venue  year  \n",
       "id                                                        \n",
       "0   international conference on management of data  1999  \n",
       "1   international conference on management of data  1999  \n",
       "2   international conference on management of data  1999  \n",
       "3   international conference on management of data  1999  \n",
       "4   international conference on management of data  1999  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfb.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare the matching properties and similarity functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the MatChain object with the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 21:23:39,670 WARNING  logging to console only\n",
      "2023-11-02 21:23:39,686 INFO     selected datasets=['test']\n",
      "2023-11-02 21:23:39,701 INFO     running command=prepare\n",
      "2023-11-02 21:23:39,703 INFO     setting seed=1\n",
      "2023-11-02 21:23:39,706 INFO     cuda available=True, embedding_device=cuda\n",
      "2023-11-02 21:23:39,708 INFO     size_1=2616, size_2=2294, concat df_data=4910\n",
      "2023-11-02 21:23:39,709 INFO     finished command=prepare, time=0.007691383361816406\n"
     ]
    }
   ],
   "source": [
    "mat = matchain.api.MatChain(dfa, dfb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to match the datasets on the properties (columns) having the same name \"year\", \"title\", \"authors\", and \"venue\", respectively. \n",
    "To do so, we have to specify the matching columns and their similarity functions. In this example, we use ```equal``` for the integer-valued column \"year\" and ```shingle_tfidf``` for each of the remaining string-valued columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.property('year', simfct='equal')\n",
    "mat.property('title', simfct='shingle_tfidf')\n",
    "mat.property('authors', simfct='shingle_tfidf')\n",
    "mat.property('venue', simfct='shingle_tfidf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These similarity functions calculate scores between 0 and 1 for pairs of property values. The higher the score, the more similar two values are.  \n",
    "\n",
    "Currently, the following similarity functions are implemented:\n",
    "- **any type**\n",
    "    - ```equal```: 1 if two values are equal and 0 otherwise.\n",
    "- **numeric type** \n",
    "    - ```absolute```\n",
    "    - ```relative```\n",
    "- **string type**\n",
    "    - ```fuzzy```: Uses library [thefuzz](https://github.com/seatgeek/thefuzz) (formerly known as fuzzywuzzy) to derive similarity values between two strings.\n",
    "    - ```tfidf```: Segments each string into words and represents it with a sparse vector of TFIDF weights for its constituent words.\n",
    "    - ```shingle_tfidf```: For each string, it computes shingles and a sparse vector with TFIDF weights for these shingles. Shingles are character-level n-grams. For example, the shingles for the string 'matchain' and $n=3$ are 'mat', 'atc', 'tch', 'cha', 'hai' and 'ain'. \n",
    "    - ```embedding```: For each string, [SentenceTransformer](https://github.com/UKPLab/sentence-transformers) generates a dense embedding vector.\n",
    "\n",
    "\n",
    "In case of ```tfidf```, ```shingle_tfidf```, and ```embedding```, similarity scores are determined as cosine similarities between the vector representations of two strings.\n",
    "\n",
    "If the ```property``` method is called several times for the same property name, the similarity scores are aggregated for this property. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the total number of record pairs grows with the product of the record sizes in datasets A and B, classifying each pair as matching or non-matching can be computationally expensive, especially for large datasets. Blocking effectively reduces the number of pairs while only discarding a small fraction of true matching pairs. The reduced set of pairs is called candidate pairs.\n",
    "\n",
    "In our example, we specify the three properties ```title```, ```authors```, and ```venue``` for blocking. The ```blocking``` method returns the candidate pairs as Pandas MultiIndex. The MultiIndex is sorted in ascending order by the first index which refers to the row index of the first dataset. The second index refers to the row index of the second dataset shifted by the number of rows of the first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 21:23:42,106 INFO     running command=blocking\n",
      "2023-11-02 21:23:42,303 INFO     generated vectors=(6567, 8257), time=0.17798328399658203, df_values=(4910, 3), df_index_array=(4910, 3), values=6567\n",
      "2023-11-02 21:23:42,367 INFO     blocking prop=title, new candidates=3649, all candidates=3649, total time nn search=0.06341695785522461\n",
      "2023-11-02 21:23:42,419 INFO     blocking prop=authors, new candidates=8067, all candidates=9230, total time nn search=0.11521339416503906\n",
      "2023-11-02 21:23:42,439 INFO     blocking prop=venue, new candidates=5200, all candidates=14385, total time nn search=0.13530826568603516\n",
      "2023-11-02 21:23:42,452 INFO     candidate pairs=14385\n",
      "2023-11-02 21:23:42,453 INFO     finished command=blocking, time=0.34694766998291016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   0, 2733),\n",
       "            (   0, 4522),\n",
       "            (   0, 4525),\n",
       "            (   1, 3415),\n",
       "            (   1, 3449),\n",
       "            (   1, 3641),\n",
       "            (   1, 3709),\n",
       "            (   1, 4130),\n",
       "            (   1, 4595),\n",
       "            (   2, 3052),\n",
       "            ...\n",
       "            (2614, 4870),\n",
       "            (2614, 4872),\n",
       "            (2614, 4874),\n",
       "            (2614, 4876),\n",
       "            (2614, 4894),\n",
       "            (2614, 4896),\n",
       "            (2614, 4898),\n",
       "            (2614, 4900),\n",
       "            (2614, 4908),\n",
       "            (2615, 4022)],\n",
       "           names=['idx_1', 'idx_2'], length=14385)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_pairs = mat.blocking(blocking_props=['title', 'authors', 'venue'])\n",
    "candidate_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, blocking reduces the number of all pairs from around 6 million to the feasible size of 14.385 candidate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "all pairs = 6001104\n",
      "candidate pairs = 14385\n"
     ]
    }
   ],
   "source": [
    "print('\\nall pairs =', len(dfa) * len(dfb))\n",
    "print('candidate pairs =', len(candidate_pairs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the ```blocking``` method allows to configure the following blocking algorithms: \n",
    "\n",
    "- **Token-Blocking**: \n",
    "    - Segments the strings for each blocking property into words (tokens) as done for similarity function ```tfidf```. Two records are considered as candidate pairs if they share at least one token.\n",
    "    - ```name='token'```\n",
    "    - All other parameters are ignored.\n",
    "- **NN on sparse vectors**: \n",
    "    - NN stands for nearest neighbour search: For each vector with respect to a string from one dataset, find the nearest vectors in relation to strings from the other dataset. Finally, all found pairs having a similarity score (cosine similarity) above a specified threshold are returned as candidate pairs.\n",
    "    - ```vector_type='shingle_tfidf'```, i.e. strings are represented as shingle vectors as described previously for similarity function ```shingle_tfidf```.\n",
    "    - ```name='sparsedottopn'``` (for library [sparse_dot_topn](https://github.com/ing-bank/sparse_dot_topn)) or ```name='nmslib'``` (for library [NMSLIB](https://github.com/nmslib/nmslib)) or ```name='sklearn'``` (for [brute force NN with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html))\n",
    "    - Parameter ```shingle_size``` is the number of characters per shingle.\n",
    "- **NN on dense vectors**: \n",
    "    - ```vector_type='embedding'```, i.e. strings are represented as embedding vectors as described previously for similarity function ```embedding```.\n",
    "    - ```name='faiss'``` (for library [Faiss](https://github.com/facebookresearch/faiss)) or ```name='sklearn'``` (for [brute force NN with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html))\n",
    "    - Parameters ```embedding_batch_size```, ```embedding_model```, and ```embedding_device``` are delegated to [SentenceTransformer](https://github.com/UKPLab/sentence-transformers).\n",
    "\n",
    "Brute force NN search finds the exact nearest neighbours but is too expensive for large datasets. By contrast, the other NN libraries usually perform only an approximate nearest neighbour search but are very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```blocking``` method declares several optional parameters. By default, it uses the following parameter values:\n",
    "\n",
    "```\n",
    "    mat.blocking(name='sparsedottopn',\n",
    "                vector_type='shingle_tfidf',\n",
    "                shingle_size=3,\n",
    "                query_strategy='smaller',\n",
    "                ntop=10,\n",
    "                blocking_threshold=0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, query strategy ```smaller``` means that for each string from the smaller dataset, (approximate) nearest neighbours from the larger dataset are searched for. Alternatively, you may choose the query strategy ```larger```, ```first```, or ```second```.  The parameter ```ntop``` specifies the number of nearest neighbours to be found. The parameter ```blocking_threshold``` determines the threshold for the similarity score of a candidate pair, i.e. only NN pairs with a similarity score greater than the threshold are returned as candidate pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoCal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoCal stands for AutoCalibration and is an unsupervised matching algorithm that is based on statistics and heuristics. It is described [here](https://como.ceb.cam.ac.uk/preprints/293/) in detail. \"Like many ML approaches, AutoCal expects the similarity features of properties as input. Since data sets frequently consist\n",
    "of a mixture of expressive properties such as plant name or locality and more or less discriminative properties, AutoCal *calibrates* automatically the similarity feature values such that they become directly comparable and summable, and uses the resulting total scores for predicting matches.\"\n",
    "\n",
    "MatChain provides a new and highly efficient implementation of AutoCal. When calling the ```autocal``` method, \n",
    "first the similarity feature values (i.e. the similarity scores) are computed for all candidate pairs and then AutoCal is started. Read the logging output of the next cell to check that both steps (commands) *similarity* and *autocal* were actually executed. However, you can also run the first step explicitly by calling the ```similarity``` method before the ```autocal``` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 21:23:45,944 INFO     running command=similarity\n",
      "2023-11-02 21:23:45,947 INFO     computing vectorized similarity\n",
      "2023-11-02 21:23:45,951 INFO     computed vectorized similarity=14385, sim columns=['0'], time=0.004377126693725586\n",
      "2023-11-02 21:23:45,952 INFO     computing similarity tfidf\n",
      "2023-11-02 21:23:46,256 INFO     computed similarity tfidf=14385, sim columns=['1', '2', '3'], time=0.3040890693664551\n",
      "2023-11-02 21:23:46,263 INFO     finished command=similarity, time=0.319171667098999\n",
      "2023-11-02 21:23:46,264 INFO     running command=autocal\n",
      "2023-11-02 21:23:46,266 INFO     calculated maximum similarity, dataset_id=1, entities=2465\n",
      "2023-11-02 21:23:46,316 INFO     calculated auto calibrated scores\n",
      "2023-11-02 21:23:46,321 INFO     identified best total scores, dataset_id=1\n",
      "2023-11-02 21:23:46,321 INFO     calculated maximum similarity, dataset_id=2, entities=2291\n",
      "2023-11-02 21:23:46,369 INFO     calculated auto calibrated scores\n",
      "2023-11-02 21:23:46,376 INFO     identified best total scores, dataset_id=2\n",
      "2023-11-02 21:23:46,380 INFO     combined total scores=14385, best total scores=2640\n",
      "2023-11-02 21:23:46,381 INFO     estimating best threshold\n",
      "2023-11-02 21:23:46,405 INFO     estimated best threshold=0.425, best pos=17\n",
      "2023-11-02 21:23:46,409 INFO     finished command=autocal, time=0.1452162265777588\n"
     ]
    }
   ],
   "source": [
    "#mat.similarity()\n",
    "mat.autocal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```predict``` method returns those candidate pairs which the matching algorithm classified as matching pairs. Once again, Pandas' MultiIndex is used to represent the matching pairs. However, this time both indices refer to the row number of the first and second dataset, respectively (without any offset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of predicted matches= 2192\n",
      "some predicted matches= [(0, 117), (1, 1093), (3, 1125), (4, 1450), (5, 49)]\n"
     ]
    }
   ],
   "source": [
    "predicted_matches = mat.predict()\n",
    "print('\\nnumber of predicted matches=', len(predicted_matches))\n",
    "print('some predicted matches=', list(predicted_matches[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of our example, the data directory ```data_dir``` also contains files for training, validation, and testing (which can be used for supervised learning). These are CSV files with pairs of row indices labeled as 0 (non-matching pair) and 1 (matching pair). The totality of all matching pairs can be used as ground truth for the unsupervised matching algorithm AutoCal. The ```evaluate``` method compares the predicted matches with the ground truth matches and computes the following metrics: F1-score *f1*, precision *p*, recall *r*, and the numbers of true positives *tpos*, false positives *fpos*, and false negatives *fneg*. Additionally, *t* stands for the matching threshold estimated by AutoCal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 21:23:49,592 INFO     running command=evaluate\n",
      "2023-11-02 21:23:49,654 INFO     metrics=\n",
      "{'blocking': {'matches': 2220, 'nonmatches': 10143, 'diff_matches': 4, 'diff_nonmatches': 8509, 'candidate_matches': 2216, 'candidate_nonmatches': 12169}, 'test_set': {'estimated': {'t': 0.425, 'f1': 0.97511, 'p': 0.97955, 'r': 0.97072, 'tpos': 431, 'fpos': 9, 'fneg': 13}}, 'union_set': {'estimated': {'t': 0.425, 'f1': 0.97416, 'p': 0.98038, 'r': 0.96802, 'tpos': 2149, 'fpos': 43, 'fneg': 71}}, 'match_frequencies_1_to_2': {0: 396, 1: 2220}, 'match_frequencies_2_to_1': {0: 74, 1: 2220}}\n",
      "2023-11-02 21:23:49,654 INFO     finished command=evaluate, time=0.062146663665771484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "metrics= {'t': 0.425, 'f1': 0.97416, 'p': 0.98038, 'r': 0.96802, 'tpos': 2149, 'fpos': 43, 'fneg': 71}\n"
     ]
    }
   ],
   "source": [
    "result = mat.evaluate(matches=data_dir)\n",
    "print('\\nmetrics=', result['union_set']['estimated'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PinBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each command is executed as soon as the corresponding method such as ```blocking```, ```similarity```, or ```autocal``` is called. If a previous step is required but was not called yet, it is executed with default values automatically. Each step stores its intermediate results in a ```board``` object. This ```board``` object can be used to inspect the current state and to access or manipulate intermediate results.\n",
    "\n",
    "For instance, the next line shows how to access the set of candidate pairs after the ```blocking``` method was called. \n",
    "\n",
    "For more details, see the documentation of class ```matchain.base.PinBoard```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(   0, 2733),\n",
       "            (   0, 4522),\n",
       "            (   0, 4525),\n",
       "            (   1, 3415),\n",
       "            (   1, 3449),\n",
       "            (   1, 3641),\n",
       "            (   1, 3709),\n",
       "            (   1, 4130),\n",
       "            (   1, 4595),\n",
       "            (   2, 3052),\n",
       "            ...\n",
       "            (2614, 4870),\n",
       "            (2614, 4872),\n",
       "            (2614, 4874),\n",
       "            (2614, 4876),\n",
       "            (2614, 4894),\n",
       "            (2614, 4896),\n",
       "            (2614, 4898),\n",
       "            (2614, 4900),\n",
       "            (2614, 4908),\n",
       "            (2615, 4022)],\n",
       "           names=['idx_1', 'idx_2'], length=14385)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.board.candidate_pairs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ontomatch3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a05e0bf576605808f99c8e3f20d8c17c8174ac0e05a4a543199cbd993da3a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
